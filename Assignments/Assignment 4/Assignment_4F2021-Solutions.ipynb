{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governments in many African countries have recently adopted fertilizer subsidies as an attempt to increase agricultural producitivity for small farmers. However there is widespread debate over whether these are effective policies. To generate evidence Carter, Lajaaj and Yang (2021) partnered with the Mozambican government to run a randomized controlled trial, in which farmers were randomly offered a voucher for subsidized fertilizer. (The paper is [Subsidies and the African Green Revolution: Direct Effects and Social Network Spillovers of Randomized Input Subsidies in Mozambique](https://www.aeaweb.org/articles?id=10.1257/app.20190396) _American Economic Journal: Applied Economics_ 13(2).)\n",
    "\n",
    "We are going to work with a subset of their data for this problem set to estimate the effects of fertilizer use on maize yields. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A:\n",
    "\n",
    "**Suppose the government did not conduct a randomized controlled trial. Instead they surveyed farmers and compared maize yields for those who did and did not use fertilizer. Would this comparison allow you to estimate the effect of fertilizer on maize yields? Explain why or why not using both words and potential outcomes notation. How would the expression for the estimated impact of fertilizer on maize yields differ if fertilizer use were randomized?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, just observing yield differences between farmers who do and don't use fertilizer would not allow us to credibly estimate the impact of fertilizer on maize yields. We think that farmers choose to use fertilizer for many reasons that may also be correlated with yields, for example, farmers who are more skilled, wealthier, grow hybrid maize varieties, have worse soil quality, etc. are probably more likely to use fertilizer, but these attributes are also likely to affect yields. So we would not be isolating the true effect of fertilizer because we would also pick up these differences by just comparing farmers who do and don't use fertilizer. \n",
    "\n",
    "In potential outcomes notation, Let $T_i$ equal 1 if farmer $i$ uses fertilizer and 0 otherwise. Let $Y^T$ be yields for farmers who use fertilizer and $Y^C$ be yields for farmers who don't. \n",
    "\n",
    "What we observe by comparing average yields across fertilizer and non-fertilizer users is \n",
    "$$E[Y^T|T=1]-E[Y^C|T=0]$$\n",
    "But what we want is $$E[Y^T|T=1]-E[Y^T|T=0]$$ i.e. what yields would have been for the group of farmers we observed using fertilizer, had they instead not used fertilizer. Of course, this counterfactual is unobservable. Adding and subtracting $E[Y^T|T=0]$ to the above gives us \n",
    "$$(E[Y^T|T=1]-E[Y^T|T=0])+(E[Y^T|T=0]-E[Y^C|T=0])$$\n",
    "The first part is equal to the true effect while the second part captures selection bias -- people who did use fertilizer would likely have different yields than those who didn't even had they not used fertilizer. \n",
    "\n",
    "Randomization allows us to recover the true effect of fertilizer by setting this selection bias term to 0. It ensures $E[Y^T|T=0]=E[Y^C|T=0]$ - i.e. farmers who do and don't use fertilizer would have the same expected yields from unfertilized maize because whether they used fertilizer was randomly determined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B:\n",
    "\n",
    "Now let's analyze the RCT data. The dataset contains observations of nine variables from 390 farm households. The variables are as follows\n",
    "- $respid$: This is just the unique ID for each farmer\n",
    "- $lyieldr$: This is the log of maize yields\n",
    "- $vouch$: This is the treatment variable of interest - equal to 1 if the household was given a voucher to purchase fertilizer (i.e. in the treatment group) and 0 otherwise (i.e in the control group)\n",
    "- $irrigprev$: This is a dummy equal to 1 if households used irrigation and 0 otherwise\n",
    "- $pestdprev$: This is a dummy equal to 1 if households used pesticides and 0 otherwise \n",
    "- $hhhmale$: This is a dummy equal to 1 if the household head is male and 0 if the household head is female\n",
    "- $hhhage$: This is the age of the household head\n",
    "- $hhheduc$: This is the number of years of education of the household head\n",
    "- $hhsize$: This is the number of members in the household \n",
    "\n",
    "Note that all variables other than maize yield were measured *before* the distribution of vouchers. For irrigation and pesticide use, they were measured the year before the voucher intervention.\n",
    "\n",
    "a) **Before running any regressions, show how you can obtain the average treatment effect (ATE) of fertilizer vouchers on (log) maize yields. Then write down the regression you could use to estimate the ATE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in average log yields between the treatment and control groups is the average treatment effect of fertilizer vouchers. Given that vouchers were randomized, any differences in log yields between the two groups can be attributed to the effect of the vouchers. In math this is just $$ATE=\\overline{\\log(yield)}_T-\\overline{\\log(yield)}_C$$\n",
    "\n",
    "Equivalently, we could run the regression\n",
    "$$\\log(yield)_i=\\beta_0+\\beta_1vouch_i+u_i$$ where $\\beta_1$ would equal the difference in log yields -- the ATE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) **Read in the data from `ps4_data.dta` (remember you need to use the `read_dta` function from the `haven` package to read `.dta` files. You will also probably want to load `tidyverse`). Then, estimate the regression you wrote down using `lm()` and test whether the ATE is statistically significant at a 95\\% confidence level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.5     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.7\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.0.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"ATE=0.208840550692112\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = lyieldr ~ vouch, data = df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.0641 -0.6338  0.0916  0.6229  4.1123 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  6.30702    0.07638  82.575   <2e-16 ***\n",
       "vouch        0.20884    0.11044   1.891   0.0594 .  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.091 on 389 degrees of freedom\n",
       "Multiple R-squared:  0.009108,\tAdjusted R-squared:  0.006561 \n",
       "F-statistic: 3.576 on 1 and 389 DF,  p-value: 0.05938\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(haven)\n",
    "library(tidyverse)\n",
    "\n",
    "df <- read_dta('ps4_data.dta')\n",
    "\n",
    "print(paste0('ATE=',mean(subset(df, vouch==1)$lyieldr)-mean(subset(df, vouch==0)$lyieldr)))\n",
    "summary(lm(lyieldr~vouch, data=df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vouchers appear to have increased yields by almost 21\\%, but with $p=.0594$ this is not quite significant at the 5\\% level (but is at 10\\%). Therefore, we fail to reject the null hypothesis that the voucher program had no effect on yields at the 5\\% level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C:\n",
    "**a) Now let's check to make sure our sample is balanced across treatment and control. For each of the four household demographics variables, conduct a t-test against the null that they are on average equal between treatment and control.**\n",
    "\n",
    "**Coding Hints**: The command for a t-test is `t.test()`. One way to test whether coviarate $X$ is correlated with treatment status $T$, you can put `X~T` inside `t.test()`, just like you would for `lm()`. If you just want to print the t-stat or the p-value rather than the entire test output, you can call `$statistic` or `$p.value`, respectively. \n",
    "\n",
    "You can repeat this separately for each covariate, but if you want to be extra fancy you can use the `lapply()` function. `lapply()` is super useful for applying a function repeatedly over different variables. The way you would use it here is `lapply(X, function (x) FUN)` where `X` is the data frame of the variables you are interested in testing and `FUN` is the function you want to apply. One of the arguments of this function should be (small) `x`, which serves as a stand-in for the column of (big) `X` that you want to apply the function over. Finally, if you want to show the output as a single data frame (instead of a list), you can wrap all of this with `as.data.frame()`. With all of this information, you could theoretically produce a nice-ish table of p-values for the four tests you run using a single line of code. You are not required or expected to use this method, but it might come in handy if you find yourself having to work with larger datasets in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>hhhmale</th><th scope=col>hhheduc</th><th scope=col>hhhage</th><th scope=col>hhsize</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.7262042</td><td>0.5804594</td><td>0.8129967</td><td>0.04358971</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 4\n",
       "\\begin{tabular}{llll}\n",
       " hhhmale & hhheduc & hhhage & hhsize\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0.7262042 & 0.5804594 & 0.8129967 & 0.04358971\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 4\n",
       "\n",
       "| hhhmale &lt;dbl&gt; | hhheduc &lt;dbl&gt; | hhhage &lt;dbl&gt; | hhsize &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 0.7262042 | 0.5804594 | 0.8129967 | 0.04358971 |\n",
       "\n"
      ],
      "text/plain": [
       "  hhhmale   hhheduc   hhhage    hhsize    \n",
       "1 0.7262042 0.5804594 0.8129967 0.04358971"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  hhhmale by vouch\n",
       "t = 0.35044, df = 383.15, p-value = 0.7262\n",
       "alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -0.05753045  0.08248589\n",
       "sample estimates:\n",
       "mean in group 0 mean in group 1 \n",
       "      0.8627451       0.8502674 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mean in group 0</dt><dd>6.66606304984467</dd><dt>mean in group 1</dt><dd>7.08251317299624</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mean in group 0] 6.66606304984467\n",
       "\\item[mean in group 1] 7.08251317299624\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mean in group 0\n",
       ":   6.66606304984467mean in group 1\n",
       ":   7.08251317299624\n",
       "\n"
      ],
      "text/plain": [
       "mean in group 0 mean in group 1 \n",
       "       6.666063        7.082513 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "as.data.frame(lapply(df[grep('^hh', names(df))], function(x) t.test(x ~ vouch, data=df)$p.value))\n",
    "t.test(hhhmale ~ vouch, data=df)\n",
    "t.test(hhsize ~ vouch, data=df)$estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the `lapply` function to run t-tests for each variable in the dataset whose name starts with 'hh' (see `?grep` for how this works), saves the p-values, and presents them in a dataframe/table. For comparison, we show the full output for the t-test for the first variable, $hhhmale$, and the means by treatment status for household size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Do you conclude that the sample is well-balanced? Are you surprised or concerned by any of the results? If so, what could you do to address your concerns?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows the p-value from each of the four hypothesis tests. We see no evidence that household head attributes (sex, years of education, or age) differ between treatment and control (here we _don't_ want to be able to reject the null that they are identical), but we see that household sizes are significantly (at 95\\% confidence) different in the treatment group. Looking at the means by group, treatment households are slightly (but significantly) bigger on average. \n",
    "\n",
    "This is a little surprising but not a cause for concern. Since we assume that we'll falsely reject the null 5\\% of the time for each hypothesis test we run at a 95\\% confidence level, we'd expect to get one false rejection from four tests about $1-0.95^4\\approx18\\%$ of the time. Remember that randomization only guarantees that treatment and control groups will be balanced in expectation. We are just dealing with one sample of 390 households, so some variables may still be correlated with treatment by chance. To address any concern about this correlation, we can always control for household size in our regression to purge our treatment effect estimates of any correlation that arose due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "**a) What happens if you control for additional covariates (household demographics and previous use of irrigation and pesticides) in this regression? What (if any) advantages are there to controlling for these variables? What (if any) disadvantages are there?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the provision of fertilizer vouchers was randomized, it should not be correlated with any other covariates. As a result, including additional covariates in the regression should not affect our estimate of the average treatment effect of the voucher program. Of course, we saw that household size is correlated with voucher receipt, so it's possible that our estimated treatment effect will change somewhat due to including this variable as a control.\n",
    "\n",
    "The advantages for controlling for variables are 1) addressing the possible affects of sample imbalances (which can happen by chance as we saw in part C) and 2) increasing precision of our estimates (reducing standard errors). If the other variables we've added explain a lot of the variation in log yields and are (for the most part) uncorrelated with $vouch$, this will reduce our standard errors (by reducing the residual variation in $u$). There are no real disadvantages to adding these variables as long as they cannot be affected by treatment (if they can be affected by treatment, we might have a 'bad controls' problem), but some people say that adding covariates in a context where treatment was randomized is unncessary because the simple regression in part B is \"good enough\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) **Run the regression controlling for all six of these variables. Interpret how your results change, if at all.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = lyieldr ~ vouch + hhhmale + hhheduc + hhhage + hhsize + \n",
       "    irrigprev + pestdprev, data = df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.0468 -0.6732  0.0744  0.6050  4.1302 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  6.413447   0.350036  18.322   <2e-16 ***\n",
       "vouch        0.224879   0.110090   2.043   0.0418 *  \n",
       "hhhmale      0.287254   0.161247   1.781   0.0756 .  \n",
       "hhheduc      0.005474   0.021105   0.259   0.7955    \n",
       "hhhage      -0.007948   0.004525  -1.756   0.0798 .  \n",
       "hhsize      -0.007872   0.027174  -0.290   0.7722    \n",
       "irrigprev    0.419174   0.269942   1.553   0.1213    \n",
       "pestdprev    0.321620   0.238140   1.351   0.1776    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.08 on 383 degrees of freedom\n",
       "Multiple R-squared:  0.04362,\tAdjusted R-squared:  0.02614 \n",
       "F-statistic: 2.495 on 7 and 383 DF,  p-value: 0.0162\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(lyieldr~vouch+hhhmale+hhheduc+hhhage+hhsize+irrigprev+pestdprev, data=df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the coefficient on $vouch$ has increased slightly (but is not statistically distinguishable from the one in part B). However, we note that it has just become statistically significant at the 5\\% level - we can now reject the null that the vouchers had no effect on maize yields. This is a benefit of the increased precision from including covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "**You think households might differ in their ability to correctly apply fertilizer in order to increase their maize yields. You hypothesize that households that use pesticides might have more knowledge about appropriate input use, so might experience larger increases in maize yields if they receive a fertilizer voucher. Propose, implement, and interpret a test of whether the effect of vouchers on log maize yields is different for households that used pesticides the prior year, building on the model from Part D.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would specify the following model:\n",
    "\n",
    "$log(yield)=\\beta_0 + \\beta_1 vouch + \\beta_2 vouch*pestdprev + \\beta_3 hhhmale + \\beta_4 hhheduc + \\beta_5 hhhage + \\beta_6 hhsize + \\beta_7 irrigprev + \\beta_8 pestdprev$\n",
    "\n",
    "In this model, $\\beta_2$ is the differential effect of the voucher treatment on log maize yield for households that used pesticide the year before. The null hypothesis we want to test is $H_0: \\beta_2=0$ against the alternative $H_1: \\beta_2\\ne 0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = lyieldr ~ vouch + vouch:pestdprev + hhhmale + hhheduc + \n",
       "    hhhage + hhsize + irrigprev + pestdprev, data = df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.0375 -0.6508  0.0630  0.5944  4.1168 \n",
       "\n",
       "Coefficients:\n",
       "                 Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)      6.406996   0.350358  18.287   <2e-16 ***\n",
       "vouch            0.205602   0.113251   1.815   0.0702 .  \n",
       "hhhmale          0.291712   0.161459   1.807   0.0716 .  \n",
       "hhheduc          0.006095   0.021134   0.288   0.7732    \n",
       "hhhage          -0.007758   0.004535  -1.711   0.0880 .  \n",
       "hhsize          -0.007809   0.027190  -0.287   0.7741    \n",
       "irrigprev        0.414364   0.270185   1.534   0.1259    \n",
       "pestdprev        0.175087   0.311020   0.563   0.5738    \n",
       "vouch:pestdprev  0.354424   0.483472   0.733   0.4640    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.081 on 382 degrees of freedom\n",
       "Multiple R-squared:  0.04496,\tAdjusted R-squared:  0.02496 \n",
       "F-statistic: 2.248 on 8 and 382 DF,  p-value: 0.02351\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(lyieldr~vouch+vouch:pestdprev+hhhmale+hhheduc+hhhage+hhsize+irrigprev+pestdprev, data=df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the coefficient on $vouch$ is similar to the previous model. Since $vouch$ now represents the average treatment effect among households that did not use pesticide the year before, this suggests there are not many households that used pesticide. The coefficient estimate on $vouch:pestdprev$ is positive and larger in magnitude, but is not statistically significant. Specifically, we have $p=0.464$, meaning we fail to reject the null that there is no differential effect of the voucher for households that used pesticide the year before at any reasonable significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F\n",
    "\n",
    "Of course, not everyone who was offered a voucher ended up redeeming it and using fertilizer. So what we've estimated so far for the average treatment effect of _receiving a fertilizer subsidy voucher on yields_  can be interpreted as an **intent to treat** estimate for the effect of  _fertilizer application on yields_.\n",
    "\n",
    "**Suppose 75\\% of people who were offered vouchers ended up using fertilizer, compared to 10\\% of people in the control group. Write down a Treatment on the Treated estimator and calculate it using your result from Part D (you don't have to run any additional regressions for this part). Under what circumstances would this be equal to the average treatment effect of using fertilizer? Do you think these hold in this context?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.345967654299587"
      ],
      "text/latex": [
       "0.345967654299587"
      ],
      "text/markdown": [
       "0.345967654299587"
      ],
      "text/plain": [
       "[1] 0.3459677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# numerator: ITT estimate\n",
    "# denominator: share of compliers\n",
    "(summary(lm(lyieldr~vouch+hhhmale+hhheduc+hhhage+hhsize+irrigprev+pestdprev, \n",
    "            data=df))$coefficients[2,1])/(.75-.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ToT is simply the ITT divided by the share of compliers (.65). We estimate that fertilizer application increases average maize yields 32.1%. \n",
    "\n",
    "Since we know that the control group is a good counterfactual for the treatment group, we can believe that 10\\% of the households in the treatment group would have used fertilizer anyways (always takers) and that 25\\% of households would not have used fertlizier even had they been given subsidy vouchers (never takers). Thus, we can infer that 65\\% of households use fertilizer if and only if they receive vouchers -- these are the only people for whom fertilizer _use_ is changing (compliers). 65% of our ITT estimate is thus the actual effect of the treatment on the treated, while the other 35% is the null effect coming from people whose behavior isn't changed by the intervention. In math, $ITT=0.65*TOT+0.35*0$.\n",
    "\n",
    "So the ToT is just the ITT weighted by the inverse of the share of compliers, or in math:\n",
    "\n",
    "$$ToT=\\frac{ITT}{\\text{% compliers}}=\\frac{\\overline{\\log(yield)}_T-\\overline{\\log(yield)}_C}{\\overline{use\\_fert}_T-\\overline{use\\_fert}_C}=\\frac{.2249}{.65}=0.346$$\n",
    "\n",
    "This is only equal to the average treatment effect of using fertilzier under two assumptions. \n",
    "1. Receiving the vouchers only affects yields through fertilizer use and\n",
    "2. The effects of fertilzier on yields are the same for compliers as they are for everyone else. \n",
    "\n",
    "There are a few different reasons 1) might not hold. People who receive fertilizer vouchers would likely alter the amounts of other inputs they use (to the extent that labor, pesticides and seeds are complements/substitutes for fertilizer). For example, hybrid seeds are much more responsive to fertilizer but generally higher yielding. If the vouchers cause people to use the money they saved on fertilizer on other inputs, then the ToT would also capture the effects of these other inputs on yields. \n",
    "\n",
    "Assumption 2) is very unlikely to hold. We think that people have different returns to fertilizer (e.g. based on skill, landholdings and soil quality) and it is quite likely that the people who stand most to gain from fertilizer use are more likely willing to pay the unsubsidized price. Conversely, people who only use fertilizer if they receive a subsidy but are not willing to pay the market price may simply be doing so because fertilizer is not very effective on their plots. So in this case $TOT<ATE$. You could also tell a story that if farmers are credit constrained and there are decreasing marginal returns to fertilizer, then the subsidy disproportionately affects credit constrained farmers that are using less fertilizer and thus have higher returns, so $TOT>ATE$. In either case, it's unlikely that these two effects would be exactly the same. Who the \"compliers\" are is always important for contextualizing effects!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
